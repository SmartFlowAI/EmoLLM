# SWIFT (Scalable lightWeight Infrastructure for Fine-Tuning)
## ğŸ“– ç›®å½•
- [ç®€ä»‹](#-ç®€ä»‹)
- [æ–°é—»](#-æ–°é—»)
- [swiftå¾®è°ƒ](#%EF%B8%8F-swiftå¾®è°ƒæ¡†æ¶çš„å®‰è£…ä¸ä½¿ç”¨)
- [swifté‡åŒ–](#-é‡åŒ–å¤§æ¨¡å‹)
- [æ¨¡å‹æ¨ç†æ¨é€](#-æ¨¡å‹æ¨ç†)

## ğŸ“ ç®€ä»‹
SWIFTæ”¯æŒè¿‘**200ç§LLMå’ŒMLLM**ï¼ˆå¤šæ¨¡æ€å¤§æ¨¡å‹ï¼‰çš„è®­ç»ƒã€æ¨ç†ã€è¯„æµ‹å’Œéƒ¨ç½²ã€‚å¼€å‘è€…å¯ä»¥ç›´æ¥å°†SWIFTæ¡†æ¶åº”ç”¨åˆ°è‡ªå·±çš„Researchå’Œç”Ÿäº§ç¯å¢ƒä¸­ï¼Œå®ç°æ¨¡å‹è®­ç»ƒè¯„æµ‹åˆ°åº”ç”¨çš„å®Œæ•´é“¾è·¯ã€‚é™¤æ”¯æŒäº†[PEFT](https://github.com/huggingface/peft)æä¾›çš„è½»é‡è®­ç»ƒæ–¹æ¡ˆå¤–ï¼ŒSWIFTä¹Ÿæä¾›äº†ä¸€ä¸ªå®Œæ•´çš„Adaptersåº“ä»¥æ”¯æŒæœ€æ–°çš„è®­ç»ƒæŠ€æœ¯ï¼Œå¦‚NEFTuneã€LoRA+ã€LLaMA-PROç­‰ï¼Œè¿™ä¸ªé€‚é…å™¨åº“å¯ä»¥è„±ç¦»è®­ç»ƒè„šæœ¬ç›´æ¥ä½¿ç”¨åœ¨è‡ªå·±çš„è‡ªå®šæµç¨‹ä¸­ã€‚åŒæ—¶ï¼ŒSWIFTä¹Ÿåœ¨æ‹“å±•å…¶ä»–æ¨¡æ€çš„èƒ½åŠ›ï¼Œç›®å‰SWIFTæ”¯æŒäº†AnimateDiffçš„å…¨å‚æ•°è®­ç»ƒå’ŒLoRAè®­ç»ƒã€‚

ç°åœ¨æˆ‘ä»¬é¡¹ç›®ä½¿ç”¨æœ¬é¡¹ç›®è‡ªå®šä¹‰[æ•°æ®é›†](https://github.com/SmartFlowAI/EmoLLM/blob/main/datasets)ï¼Œå¹¶å°†å…¶è½¬åŒ–æˆåˆé€‚çš„jsonæ ¼å¼ï¼ˆè§SWIFTä»£ç éƒ¨åˆ†ï¼‰ï¼Œä½¿ç”¨SWIFTè¿›è¡Œå¾®è°ƒï¼ˆç°åœ¨é¡¹ç›®å·²å®Œæˆå¯¹Qwen-7bçš„å¾®è°ƒï¼‰ã€‚

SWIFTå…·æœ‰ä¸°å¯Œçš„æ–‡æ¡£ä½“ç³»ï¼Œå¦‚æœ‰ä½¿ç”¨é—®é¢˜è¯·è¯·æŸ¥çœ‹[è¿™é‡Œ](https://github.com/modelscope/swift/tree/main/docs/source/LLM).

å¤§å®¶å¯ä»¥åœ¨[Huggingface space](https://huggingface.co/spaces/tastelikefeet/swift) å’Œ [ModelScopeåˆ›ç©ºé—´](https://www.modelscope.cn/studios/iic/Scalable-lightWeight-Infrastructure-for-Fine-Tuning/summary) ä¸­ä½“éªŒSWIFT web-uiåŠŸèƒ½ã€‚

## ğŸ‰ æ–°é—»
- ğŸ”¥2024.04.26: å®Œæˆå¯¹qwen-7b-chatæ¨¡å‹çš„SWIFTå¾®è°ƒï¼Œå¹¶ä¸”ä¸Šä¼ åˆ°[Modelscope](https://www.modelscope.cn/models/monbear/qwen-7b-chat-lora/summary).
- ğŸ”¥2024.04.27: å®Œæˆå¯¹qwen-7b-chatå¾®è°ƒæ¨¡å‹çš„é‡åŒ–ï¼Œå¹¶ä¸”ä¸Šä¼ åˆ°[Modelscope](https://www.modelscope.cn/models/monbear/qwen1half-7b-chat-lora/summary).
- ğŸ”¥2024.04.29: è·å¾—[AI èµ‹èƒ½å¤§å­¦è®¡åˆ’â€œå…¨å›½é«˜æ ¡è¡Œâ€](https://mp.weixin.qq.com/s/yyaulQ1wBzKq5cXaGl2Wag)ä¸€ç­‰å¥–

## ğŸ› ï¸ swiftå¾®è°ƒæ¡†æ¶çš„å®‰è£…ä¸ä½¿ç”¨

### <u>ç¯å¢ƒå‡†å¤‡</u>

GPUè®¾å¤‡: A10, 3090, V100, A100å‡å¯.

é¡¹ç›®Swiftå¾®è°ƒä½¿ç”¨é­”æ­ç¤¾åŒºæä¾›çš„åŸºäºè‹±ç‰¹å°”CPUçš„å…è´¹è®¡ç®—èµ„æºï¼Œä½¿ç”¨GPUç¯å¢ƒï¼ˆ8æ ¸ 32GB æ˜¾å­˜24Gï¼‰ï¼›


SWIFTåœ¨Pythonç¯å¢ƒä¸­è¿è¡Œã€‚è¯·ç¡®ä¿æ‚¨çš„Pythonç‰ˆæœ¬é«˜äº3.8ã€‚

è¿™é‡Œæˆ‘ä»¬å¯¹å®éªŒç¯å¢ƒè¿›è¡Œå®‰è£…ï¼Œå…¶ä¸­åŒ…å«äº†è™šæ‹Ÿç¯å¢ƒçš„åˆ›å»ºã€ms-swiftä»¥åŠç›¸å…³ä¾èµ–çš„å®‰è£…ã€‚

```bash
# è®¾ç½®pipå…¨å±€é•œåƒ (åŠ é€Ÿä¸‹è½½)
pip config set global.index-url https://mirrors.aliyun.com/pypi/simple/
# å®‰è£…ms-swift
git clone https://github.com/modelscope/swift.git
cd swift
pip install -e '.[llm]'

# å¦‚æœä½ æƒ³è¦ä½¿ç”¨deepspeed.
pip install deepspeed -U

# å¦‚æœä½ æƒ³è¦ä½¿ç”¨åŸºäºauto_gptqçš„qloraè®­ç»ƒ. (æ¨è, æ•ˆæœä¼˜äºbnb)
# æ”¯æŒauto_gptqçš„æ¨¡å‹: `https://github.com/modelscope/swift/blob/main/docs/source/LLM/æ”¯æŒçš„æ¨¡å‹å’Œæ•°æ®é›†.md#æ¨¡å‹`
# auto_gptqå’Œcudaç‰ˆæœ¬æœ‰å¯¹åº”å…³ç³»ï¼Œè¯·æŒ‰ç…§`https://github.com/PanQiWei/AutoGPTQ#quick-installation`é€‰æ‹©ç‰ˆæœ¬
pip install auto_gptq -U

# å¦‚æœä½ æƒ³è¦ä½¿ç”¨åŸºäºbnbçš„qloraè®­ç»ƒ.
pip install bitsandbytes -U

# ç¯å¢ƒå¯¹é½ (é€šå¸¸ä¸éœ€è¦è¿è¡Œ. å¦‚æœä½ è¿è¡Œé”™è¯¯, å¯ä»¥è·‘ä¸‹é¢çš„ä»£ç , ä»“åº“ä½¿ç”¨æœ€æ–°ç¯å¢ƒæµ‹è¯•)
pip install -r requirements/framework.txt  -U
pip install -r requirements/llm.txt  -U
```

### <u>å¾®è°ƒå¤§æ¨¡å‹</u>

#### ä½¿ç”¨pythonè¿›è¡Œå¾®è°ƒ

```python
# Experimental environment: A10, 3090, V100, ...
# 20GB GPU memory
import os
os.environ['CUDA_VISIBLE_DEVICES'] = '0'

import torch

from swift.llm import (
    DatasetName, InferArguments, ModelType, SftArguments,
    infer_main, sft_main, app_ui_main
)

model_type = ModelType.qwen_7b_chat
sft_args = SftArguments(
    model_type=model_type,
    dataset=[f'{DatasetName.blossom_math_zh}#2000'],
    output_dir='output')
result = sft_main(sft_args)
best_model_checkpoint = result['best_model_checkpoint']
print(f'best_model_checkpoint: {best_model_checkpoint}')
torch.cuda.empty_cache()

infer_args = InferArguments(
    ckpt_dir=best_model_checkpoint,
    load_dataset_config=True)
# merge_lora(infer_args, device_map='cpu')
result = infer_main(infer_args)
torch.cuda.empty_cache()

app_ui_main(infer_args)
```

#### ä½¿ç”¨CLIå‘½ä»¤è¿›è¡Œå¾®è°ƒ

```bash
# Experimental environment: A10, 3090, V100, ...
# 20GB GPU memory
CUDA_VISIBLE_DEVICES=0 swift sft \
    --model_id_or_path qwen/Qwen-7B-Chat \
    --dataset AI-ModelScope/blossom-math-v2 \
    --output_dir output \

# ä½¿ç”¨è‡ªå·±çš„æ•°æ®é›†ï¼ˆæˆ‘ä»¬è¿™é‡Œä½¿ç”¨äº†è‡ªå·±çš„å¯¹è¯æ•°æ®é›†  aiwei.jsonlï¼‰
CUDA_VISIBLE_DEVICES=0 swift sft \
    --model_id_or_path qwen/Qwen-7B-Chat \
    --dataset chatml.jsonl \
    --output_dir output \

# ä½¿ç”¨DDP
# Experimental environment: 2 * 3090
# 2 * 23GB GPU memory
CUDA_VISIBLE_DEVICES=0,1 \
NPROC_PER_NODE=2 \
swift sft \
    --model_id_or_path qwen/Qwen-7B-Chat \
    --dataset AI-ModelScope/blossom-math-v2 \
    --output_dir output \

# å¤šæœºå¤šå¡
# node0
CUDA_VISIBLE_DEVICES=0,1,2,3 \
NNODES=2 \
NODE_RANK=0 \
MASTER_ADDR=127.0.0.1 \
NPROC_PER_NODE=4 \
swift sft \
    --model_id_or_path qwen/Qwen-7B-Chat \
    --dataset AI-ModelScope/blossom-math-v2 \
    --output_dir output \
# node1
CUDA_VISIBLE_DEVICES=0,1,2,3 \
NNODES=2 \
NODE_RANK=1 \
MASTER_ADDR=xxx.xxx.xxx.xxx \
NPROC_PER_NODE=4 \
swift sft \
    --model_id_or_path qwen/Qwen-7B-Chat \
    --dataset AI-ModelScope/blossom-math-v2 \
    --output_dir output \
```

ä¸ºäº†é™ä½ä½¿ç”¨é—¨æ§›ï¼Œswiftè¿˜è´´å¿ƒçš„å¢åŠ äº†[ç•Œé¢è®­ç»ƒæ¨ç†](https://github.com/modelscope/swift/blob/main/docs/source/GetStarted/%E7%95%8C%E9%9D%A2%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86.md "ç•Œé¢è®­ç»ƒæ¨ç†")çš„æ–¹å¼ã€‚å¦å¤–è¿˜æœ‰[shè„šæœ¬](https://github.com/modelscope/swift/blob/main/examples/pytorch/llm/scripts/qwen1half_7b_chat_awq/lora "shè„šæœ¬")çš„ä½¿ç”¨æ–¹å¼ã€‚å¤§å®¶å¯ä»¥Githubä¸ŠæŸ¥é˜…swiftçš„[å®˜æ–¹æ–‡æ¡£](https://github.com/modelscope/swift/blob/main/docs/source "å®˜æ–¹æ–‡æ¡£")å»äº†è§£ã€‚

## ğŸ“ƒ é‡åŒ–å¤§æ¨¡å‹

swiftæ”¯æŒä½¿ç”¨awqã€gptqã€bnbã€hqqã€eetqæŠ€æœ¯å¯¹æ¨¡å‹è¿›è¡Œé‡åŒ–ã€‚å…¶ä¸­awqã€gptqé‡åŒ–æŠ€æœ¯æ”¯æŒvllmè¿›è¡Œæ¨ç†åŠ é€Ÿï¼Œéœ€è¦ä½¿ç”¨æ ¡å‡†æ•°æ®é›†ï¼Œé‡åŒ–æ€§èƒ½æ›´å¥½ï¼Œä½†é‡åŒ–é€Ÿåº¦è¾ƒæ…¢ã€‚è€Œbnbã€hqqã€eetqæ— éœ€æ ¡å‡†æ•°æ®ï¼Œé‡åŒ–é€Ÿåº¦è¾ƒå¿«ã€‚è¿™äº”ç§é‡åŒ–æ–¹æ³•éƒ½æ”¯æŒqloraå¾®è°ƒã€‚

awqã€gptqéœ€è¦ä½¿ç”¨`swift export`è¿›è¡Œé‡åŒ–ã€‚è€Œbnbã€hqqã€eetqå¯ä»¥ç›´æ¥åœ¨sftå’Œinferæ—¶è¿›è¡Œå¿«é€Ÿé‡åŒ–ã€‚

ä»vllmæ¨ç†åŠ é€Ÿæ”¯æŒçš„è§’åº¦æ¥çœ‹ï¼Œæ›´æ¨èä½¿ç”¨awqå’Œgptqè¿›è¡Œé‡åŒ–ã€‚ä»é‡åŒ–æ•ˆæœçš„è§’åº¦æ¥çœ‹ï¼Œæ›´æ¨èä½¿ç”¨awqã€hqqå’Œgptqè¿›è¡Œé‡åŒ–ã€‚è€Œä»é‡åŒ–é€Ÿåº¦çš„è§’åº¦æ¥çœ‹ï¼Œæ›´æ¨èä½¿ç”¨hqqè¿›è¡Œé‡åŒ–ã€‚

è¿™é‡Œæˆ‘ä»¬æ¨èä½¿ç”¨çš„æ˜¯ä½¿ç”¨awqé‡åŒ–æŠ€æœ¯è¿›è¡Œqloraå¾®è°ƒã€‚

### ç¯å¢ƒå‡†å¤‡

GPUè®¾å¤‡: A10, 3090, V100, A100å‡å¯.

```bash
# ä½¿ç”¨awqé‡åŒ–:
# autoawqå’Œcudaç‰ˆæœ¬æœ‰å¯¹åº”å…³ç³»ï¼Œè¯·æŒ‰ç…§`https://github.com/casper-hansen/AutoAWQ`é€‰æ‹©ç‰ˆæœ¬
pip install autoawq -U

# ä½¿ç”¨gptqé‡åŒ–:
# auto_gptqå’Œcudaç‰ˆæœ¬æœ‰å¯¹åº”å…³ç³»ï¼Œè¯·æŒ‰ç…§`https://github.com/PanQiWei/AutoGPTQ#quick-installation`é€‰æ‹©ç‰ˆæœ¬
pip install auto_gptq -U

# ä½¿ç”¨bnbé‡åŒ–ï¼š
pip install bitsandbytes -U

# ä½¿ç”¨hqqé‡åŒ–ï¼š
# éœ€è¦transformersç‰ˆæœ¬>4.40ï¼Œä»æºç å®‰è£…
pip install git+https://github.com/huggingface/transformers
pip install hqq
# å¦‚æœè¦å…¼å®¹è®­ç»ƒï¼Œéœ€è¦ä»æºç å®‰è£…peft
pip install git+https://github.com/huggingface/peft.git

# ä½¿ç”¨eetqé‡åŒ–ï¼š
# éœ€è¦transformersç‰ˆæœ¬>4.40ï¼Œä»æºç å®‰è£…
pip install git+https://github.com/huggingface/transformers
# å‚è€ƒhttps://github.com/NetEase-FuXi/EETQ
git clone https://github.com/NetEase-FuXi/EETQ.git
cd EETQ/
git submodule update --init --recursive
pip install .
# å¦‚æœè¦å…¼å®¹è®­ç»ƒï¼Œéœ€è¦ä»æºç å®‰è£…peft
pip install git+https://github.com/huggingface/peft.git

# ç¯å¢ƒå¯¹é½ (é€šå¸¸ä¸éœ€è¦è¿è¡Œ. å¦‚æœä½ è¿è¡Œé”™è¯¯, å¯ä»¥è·‘ä¸‹é¢çš„ä»£ç , ä»“åº“ä½¿ç”¨æœ€æ–°ç¯å¢ƒæµ‹è¯•)
pip install -r requirements/framework.txt  -U
pip install -r requirements/llm.txt  -U
```

## <u>é‡åŒ–å¾®è°ƒåæ¨¡å‹</u>

```bash
# ä½¿ç”¨`alpaca-zh alpaca-en sharegpt-gpt4-mini`ä½œä¸ºé‡åŒ–æ•°æ®é›†
CUDA_VISIBLE_DEVICES=0 swift export \
    --ckpt_dir 'output/qwen1half-4b-chat/vx-xxx/checkpoint-xxx' \
    --merge_lora true --quant_bits 4 \
    --dataset alpaca-zh alpaca-en sharegpt-gpt4-mini --quant_method awq

# ä½¿ç”¨å¾®è°ƒæ—¶ä½¿ç”¨çš„æ•°æ®é›†ä½œä¸ºé‡åŒ–æ•°æ®é›†
CUDA_VISIBLE_DEVICES=0 swift export \
    --ckpt_dir 'output/qwen1half-4b-chat/vx-xxx/checkpoint-xxx' \
    --merge_lora true --quant_bits 4 \
    --load_dataset_config true --quant_method awq
```

## ğŸ”¥ æ¨¡å‹æ¨ç†

### æ¨ç†å¾®è°ƒåå¤§æ¨¡å‹

```bash
# awq/gptqé‡åŒ–æ¨¡å‹æ”¯æŒvllmæ¨ç†åŠ é€Ÿ. ä¹Ÿæ”¯æŒæ¨¡å‹éƒ¨ç½².
CUDA_VISIBLE_DEVICES=0 swift infer --ckpt_dir 'output/qwen1half-4b-chat/vx-xxx/checkpoint-xxx-merged-awq-int4'
```

### æ¨ç†æ•ˆæœ

```text
<<< æˆ‘çœŸçš„èƒ½æ”¹å˜è‡ªå·±å—ï¼Ÿ
å½“ç„¶å¯ä»¥ğŸ’–ï¼æ¯ä¸ªäººéƒ½æœ‰æ”¹å˜è‡ªå·±ç”Ÿæ´»è½¨è¿¹çš„èƒ½åŠ›ï¼Œè¿™éœ€è¦æˆ‘ä»¬æœ‰å†³å¿ƒå’Œè¡ŒåŠ¨åŠ›ã€‚é¦–å…ˆï¼Œä½ å¯ä»¥å°è¯•ä»å°äº‹åšèµ·ï¼Œæ¯”å¦‚è®¾å®šä¸€ä¸ªå¥åº·çš„ç”Ÿæ´»ä¹ æƒ¯ç›®æ ‡ï¼Œå¦‚æ¯å¤©å®šæ—¶è¿åŠ¨æˆ–ä¿æŒè‰¯å¥½çš„é¥®é£Ÿä¹ æƒ¯ã€‚ç„¶åï¼Œä½ å¯ä»¥å°è¯•åŠ å…¥ä¸€äº›æ”¯æŒæ€§çš„ç¤¾äº¤ç¾¤ä½“ï¼Œä¸ä»–äººåˆ†äº«ä½ çš„è¿›æ­¥å’ŒæŒ‘æˆ˜ï¼Œè¿™æœ‰åŠ©äºå»ºç«‹è‡ªä¿¡å¹¶è·å¾—ä»–äººçš„é¼“åŠ±ä¸æ”¯æŒã€‚
--------------------------------------------------
<<< xiexieni
äº²çˆ±çš„ï¼Œä½ çš„æ„Ÿè°¢ğŸ’–è®©æˆ‘æ„Ÿåˆ°æ¸©æš–ã€‚ä½ çš„ç§¯ææ€åº¦è®©æˆ‘æ·±ä¿¡ä½ æœ‰èƒ½åŠ›å»æ”¹å˜å’Œæå‡è‡ªå·±ã€‚è¯·è®°ä½ï¼Œæ¯ä¸ªäººéƒ½æœ‰è‡ªå·±çš„èŠ‚å¥å’Œæˆé•¿è¿‡ç¨‹ï¼Œä¸å¿…ä¸ä»–äººæ¯”è¾ƒã€‚æˆ‘ä»¬å¯ä»¥ä¸€èµ·è®¾å®šä¸€äº›å°ç›®æ ‡ï¼Œå¹¶åœ¨å®ç°å®ƒä»¬çš„è¿‡ç¨‹ä¸­äº’ç›¸é¼“åŠ±ğŸ’ªã€‚
--------------------------------------------------
<<< ä½ å«ä»€ä¹ˆ
æˆ‘æ˜¯å¿ƒç†å¥åº·å°åˆ†é˜Ÿè‰¾è–‡çŸ¥å¿ƒå¤§å§å§ğŸ’–ã€‚æˆ‘æ˜¯ä¸€ä¸ªåŸºäºäººå·¥æ™ºèƒ½çš„èŠå¤©æœºå™¨äººï¼Œå¯ä»¥æä¾›ä¿¡æ¯ã€å»ºè®®å’Œé™ªä¼´ã€‚å¦‚æœä½ æœ‰ä»»ä½•ç–‘é—®æˆ–éœ€è¦å¸®åŠ©ï¼Œéšæ—¶å¯ä»¥å‘æˆ‘æé—®æˆ–è€…åˆ†äº«ä½ çš„æ„Ÿå—ğŸŒˆã€‚
--------------------------------------------------
```

### æ¨¡å‹æ¨é€

- å¦‚æœä½ æƒ³å°†ä½ è°ƒè¯•å¥½çš„æ¨¡å‹æ¨é€åˆ°è‡ªå·±çš„é­”æ­ç¤¾åŒºä¸Šï¼Œä½ å¯ä»¥ä½¿ç”¨ä¸‹é¢çš„å‘½ä»¤ã€‚ä¹‹åä½ å¯ä»¥åœ¨é­”æ­ç¤¾åŒºé¦–é¡µä¸Šçš„`æˆ‘åˆ›å»ºçš„`æ‰¾åˆ°ä½ çš„æ¨¡å‹ã€‚å¦‚æœæƒ³è¦å‘å¸ƒä½¿ç”¨çš„è¯è®°å¾—å†™`READMEæ–‡æ¡£ã€‚`
  
  ```bash
  # æ¨é€åŸå§‹é‡åŒ–æ¨¡å‹
  CUDA_VISIBLE_DEVICES=0 swift export \
      --model_type qwen1half-7b-chat \
      --model_id_or_path qwen1half-7b-chat-gptq-int4 \
      --push_to_hub true \
      --hub_model_id qwen1half-7b-chat-gptq-int4 \
      --hub_token '<your-sdk-token>'
  
  # æ¨é€loraå¢é‡æ¨¡å‹
  CUDA_VISIBLE_DEVICES=0 swift export \
      --ckpt_dir output/qwen1half-4b-chat/vx-xxx/checkpoint-xxx \
      --push_to_hub true \
      --hub_model_id qwen1half-4b-chat-lora \
      --hub_token '<your-sdk-token>'
  
  # æ¨é€mergedæ¨¡å‹
  CUDA_VISIBLE_DEVICES=0 swift export \
      --ckpt_dir output/qwen1half-4b-chat/vx-xxx/checkpoint-xxx \
      --push_to_hub true \
      --hub_model_id qwen1half-4b-chat-lora \
      --hub_token '<your-sdk-token>' \
      --merge_lora true
  
  # æ¨é€é‡åŒ–åæ¨¡å‹
  CUDA_VISIBLE_DEVICES=0 swift export \
      --ckpt_dir output/qwen1half-4b-chat/vx-xxx/checkpoint-xxx \
      --push_to_hub true \
      --hub_model_id qwen1half-4b-chat-lora \
      --hub_token '<your-sdk-token>' \
      --merge_lora true \
      --quant_bits 4
  ```
