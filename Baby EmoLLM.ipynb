{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bce0c8b8821b006",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Baby EmoLLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894e9316",
   "metadata": {},
   "source": [
    "- æœ¬æ•™ç¨‹åˆ†ä¸ºä¸¤ä¸ªéƒ¨åˆ†ï¼šæ¨¡å‹å¾®è°ƒå’ŒRAG\n",
    "- è¿™é‡Œåªåšç®€å•çš„æµç¨‹æ¼”ç¤ºï¼Œè®©å¤§å®¶æ˜ç™½æ¨¡å‹å¾®è°ƒå’ŒRAGåŸºæœ¬åŸç†\n",
    "- æœ¬é¡¹ç›®ä½¿ç”¨çš„å¾®è°ƒæ¡†æ¶ä¸ºXTuner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e688ce4",
   "metadata": {},
   "source": [
    "## æ¨¡å‹å¾®è°ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051e0571",
   "metadata": {},
   "source": [
    "### ç¯å¢ƒå®‰è£…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9a03da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install transformers\n",
    "# ! pip install torch\n",
    "# ! pip install datasets\n",
    "# ! pip install peft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e871bbbde40410ac",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### å¯¼å…¥ç›¸å…³åŒ…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "569bb07e89714c78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T12:19:35.361923Z",
     "start_time": "2024-04-11T12:19:27.648057Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForSeq2Seq, TrainingArguments, Trainer\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa86a98",
   "metadata": {},
   "source": [
    "### æ¨¡å‹ä¸‹è½½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e75bd70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T13:29:50.286054Z",
     "start_time": "2024-04-08T13:20:20.776157Z"
    }
   },
   "outputs": [],
   "source": [
    "# from modelscope.hub.snapshot_download import snapshot_download\n",
    "# snapshot_download(model_id=\"Shanghai_AI_Laboratory/internlm2-chat-1_8b\", cache_dir=\"./models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb967007",
   "metadata": {},
   "source": [
    "### åŠ è½½æ•°æ®é›†"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455d51dd6b964c8c",
   "metadata": {},
   "source": [
    "- æœ¬é¡¹ç›®çš„æ‰€æœ‰æ•°æ®é›†å­˜å‚¨åœ¨`./datasets`æ–‡ä»¶å¤¹ä¸‹\n",
    "- æ•°æ®é›†çš„ä»‹ç»è¯·å‚è€ƒ`./datasets/README.md`\n",
    "- å¾®è°ƒæ•°æ®é›†çš„æ„å»ºæŒ‡å—è¯·å‚è€ƒ`./generate_data/tutorial.md`\n",
    "- æœ¬å®éªŒçš„å¾®è°ƒæ•°æ®é›†ä¸º`./datasets/processed_single_turn_dataset_1.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f81f6cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['conversation'],\n",
       "    num_rows: 14041\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds= load_dataset(\"json\",  data_files=\"./datasets/processed_single_turn_dataset_1.json\", split=\"train\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d41d0a2",
   "metadata": {},
   "source": [
    "### åŠ è½½æ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7283eaa040ff8be",
   "metadata": {},
   "source": [
    "- æœ¬å®éªŒçš„æ¨¡å‹é‡‡ç”¨çš„æ¨¡å‹ä¸º`internlm2-chat-1_8b`\n",
    "- ä½ ä¹Ÿå¯ä»¥å°†æ¨¡å‹æ›´æ¢ä¸ºå…¶ä»–æ¨¡å‹\n",
    "- å¾®è°ƒç­–ç•¥é‡‡ç”¨çš„æ˜¯`QLoRA`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad32bc51f11a16d6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57a37656a238455c824c90e8a605f875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_dir = \"./Shanghai_AI_Laboratory/internlm2-chat-1_8b\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_dir, low_cpu_mem_usage=True, \n",
    "                                            torch_dtype=torch.bfloat16,\n",
    "                                            device_map=\"auto\",\n",
    "                                            load_in_4bit=True,\n",
    "                                            bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "                                            bnb_4bit_quant_type=\"nf4\",\n",
    "                                            bnb_4bit_use_double_quant=True,\n",
    "                                            trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4d9e7c",
   "metadata": {},
   "source": [
    "### æ•°æ®é¢„å¤„ç†"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d1e0c5d2c3f007",
   "metadata": {},
   "source": [
    "- æ„é€ æ•°æ®å¤„ç†å‡½æ•°ï¼Œå°†æ•°æ®é›†ä¸­çš„å¯¹è¯è½¬æ¢ä¸ºæ¨¡å‹çš„è¾“å…¥æ ¼å¼\n",
    "- å½“æˆ‘ä»¬ä½¿ç”¨Xtunerè¿›è¡Œå¾®è°ƒæ—¶ï¼Œæ•°æ®å¤„ç†ä¼šè‡ªåŠ¨è¿›è¡Œï¼Œæ— éœ€æ‰‹åŠ¨å¤„ç†\n",
    "- æˆ‘ä»¬åªéœ€è¦æä¾›å¤„ç†å¥½çš„å¯¹è¯æ•°æ®å³å¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e081c211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_func(example):\n",
    "    MAX_LENGTH = 512\n",
    "    input_ids, attention_mask, labels = [], [], []\n",
    "    instruction = example[\"conversation\"][0][\"input\"]\n",
    "    instruction = model.build_inputs(tokenizer, instruction, history=[], meta_instruction=example[\"conversation\"][0][\"system\"])  \n",
    "    response = tokenizer(example[\"conversation\"][0][\"output\"], add_special_tokens=False)       \n",
    "\n",
    "    \n",
    "    input_ids = instruction[\"input_ids\"][0].numpy().tolist() + response[\"input_ids\"] + [tokenizer.eos_token_id]\n",
    "    attention_mask = instruction[\"attention_mask\"][0].numpy().tolist() + response[\"attention_mask\"] + [1]\n",
    "    labels = [-100] * len(instruction[\"input_ids\"][0].numpy().tolist()) + response[\"input_ids\"] + [tokenizer.eos_token_id]\n",
    "\n",
    "\n",
    "    if len(input_ids) > MAX_LENGTH:\n",
    "        input_ids = input_ids[:MAX_LENGTH]\n",
    "        attention_mask = attention_mask[:MAX_LENGTH]\n",
    "        labels = labels[:MAX_LENGTH]\n",
    "\n",
    "    \n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f4c1886",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function process_func at 0x7fefd48c6b00> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d5fd61a7fee4a0e85f717df368aa334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14041 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 14041\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds = ds.map(process_func, remove_columns=ds.column_names)\n",
    "tokenized_ds "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea3583a",
   "metadata": {},
   "source": [
    "### é…ç½®QLoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5815525df43b36f2",
   "metadata": {},
   "source": [
    "- QLoRAæ˜¯ä¸€ç§é«˜æ•ˆçš„å¤§æ¨¡å‹å¾®è°ƒç­–ç•¥\n",
    "- åœ¨å¾®è°ƒæ—¶ï¼Œæˆ‘ä»¬å¯ä»¥é€‰æ‹©å¯¹æ¨¡å‹çš„éƒ¨åˆ†å‚æ•°è¿›è¡Œå¾®è°ƒ\n",
    "- é€šè¿‡é…ç½®`LoraConfig`ï¼Œæˆ‘ä»¬å¯ä»¥æŒ‡å®šå¾®è°ƒçš„ç›®æ ‡æ¨¡å—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c622561",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "config = LoraConfig(task_type=TaskType.CAUSAL_LM, target_modules=[\"wqkv\", \"w1\", \"w2\", \"w3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c11fa72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type=<TaskType.CAUSAL_LM: 'CAUSAL_LM'>, inference_mode=False, r=8, target_modules=['wqkv', 'w1', 'w2', 'w3'], lora_alpha=8, lora_dropout=0.0, fan_in_fan_out=False, bias='none', modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None)\n"
     ]
    }
   ],
   "source": [
    "# æŸ¥çœ‹QLoRAé…ç½®æ–‡ä»¶\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07fb8f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_peft_model(model, config)  # æ ¹æ®é…ç½®æ–‡ä»¶åœ¨åŸæ¨¡å‹çš„åŸºç¡€ä¸Šæ·»åŠ QLoRAæ¨¡å—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e3292d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.enable_input_require_grads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "490a71f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 7,077,888 || all params: 1,896,187,904 || trainable%: 0.37326933607525004\n"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f7e637",
   "metadata": {},
   "source": [
    " trainable params ï¼šè¡¨ç¤ºå‚ä¸è®­ç»ƒçš„å‚æ•°é‡\n",
    " all params ï¼š æ¨¡å‹çš„æ•´ä¸ªå‚æ•°é‡\n",
    " trainable ï¼š å‚ä¸è®­ç»ƒçš„å‚æ•°å æ•´ä¸ªå‚æ•°çš„æ¯”ä¾‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d78f40",
   "metadata": {},
   "source": [
    "### é…ç½®è®­ç»ƒå‚æ•°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921d077eb0694af5",
   "metadata": {},
   "source": [
    "- æˆ‘ä»¬å¯ä»¥é€šè¿‡`TrainingArguments`æ¥é…ç½®è®­ç»ƒå‚æ•°\n",
    "- output_dir: QLoRAæ¨¡å‹ä¿å­˜è·¯å¾„\n",
    "- per_device_train_batch_size: æ¯ä¸ªè®¾å¤‡çš„è®­ç»ƒbatch_size\n",
    "- gradient_accumulation_steps: æ¢¯åº¦ç´¯ç§¯æ­¥æ•°\n",
    "- logging_steps: æ—¥å¿—è¾“å‡ºæ­¥æ•°\n",
    "- num_train_epochs: è®­ç»ƒè½®æ•°\n",
    "- learning_rate: å­¦ä¹ ç‡\n",
    "- gradient_checkpointing: æ¢¯åº¦æ£€æŸ¥ç‚¹\n",
    "- optim: ä¼˜åŒ–å™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e735e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"./chatbot\",\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=16,\n",
    "    logging_steps=10,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=3e-4,\n",
    "    gradient_checkpointing=True,\n",
    "    optim=\"paged_adamw_32bit\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1c155e",
   "metadata": {},
   "source": [
    "### åˆ›å»ºè®­ç»ƒå™¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b52b744",
   "metadata": {},
   "source": [
    "- model ï¼š åŠ è½½äº†QLoRAé€‚é…å™¨çš„model\n",
    "- args : è®­ç»ƒçš„å‚æ•°é…ç½®\n",
    "- train_dataset ï¼š å¤„ç†åçš„è®­ç»ƒæ•°æ®é›†\n",
    "- data_collator ï¼š æ•°æ®é›†è§„æ•´å™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf7735cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_ds,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51197e20",
   "metadata": {},
   "source": [
    "### æ¨¡å‹è®­ç»ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcae7f07281f996",
   "metadata": {},
   "source": [
    "- å®Œæˆä»¥ä¸Šæ­¥éª¤åï¼Œæˆ‘ä»¬å¯ä»¥å¼€å§‹è®­ç»ƒæ¨¡å‹\n",
    "- æœ¬é¡¹ç›®æ‰€æœ‰çš„è®­ç»ƒè„šæœ¬éƒ½å­˜å‚¨åœ¨`xtuner_config`æ–‡ä»¶å¤¹ä¸‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8e069e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9404be5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f571a31",
   "metadata": {},
   "source": [
    "### æ¨¡å‹è¯„ä¼°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3528d3ca7e4e1f06",
   "metadata": {},
   "source": [
    "- åŒæ—¶åŠ è½½è®­ç»ƒå¥½çš„QLoRAæ¨¡å‹å’ŒåŸå§‹æ¨¡å‹è¿›è¡Œæ¨ç†è¯„ä¼°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12504ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "p_model = PeftModel.from_pretrained(model, model_id=\"./chatbot/checkpoint-876\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8cdca4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æˆ‘å¾ˆç†è§£ä½ å¯¹å¿ƒç†å¥åº·çš„å…³æ³¨ã€‚å¿ƒç†å¥åº·å°±åƒæ˜¯ä¸€æ£µèŒ‚ç››çš„æ ‘ï¼Œéœ€è¦æˆ‘ä»¬ç»†å¿ƒå‘µæŠ¤ã€‚å°±åƒæ ‘çš„æ ¹ç³»ä¸€æ ·ï¼Œå¿ƒç†å¥åº·éœ€è¦æˆ‘ä»¬çš„ç§¯ææ€è€ƒã€ä¹è§‚çš„å¿ƒæ€å’Œæœ‰æ•ˆçš„åº”å¯¹å‹åŠ›çš„èƒ½åŠ›ã€‚\n",
      "\n",
      "æœ‰æ—¶å€™ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šæ„Ÿåˆ°å¿ƒç†ä¸å¥åº·ï¼Œè¿™å¯èƒ½æ˜¯å› ä¸ºæˆ‘ä»¬é¢ä¸´ç€ä¸€äº›æŒ‘æˆ˜å’Œå‹åŠ›ã€‚å°±åƒåœ¨æš´é£é›¨ä¸­ï¼Œæ ‘å¯èƒ½ä¼šæ‘‡æ‘‡æ¬²å ï¼Œä½†æ˜¯åªè¦æˆ‘ä»¬åšå®ˆï¼Œå®ƒå°±ä¼šæ¢å¤å¥åº·ã€‚æ‰€ä»¥ï¼Œå½“ä½ æ„Ÿåˆ°å¿ƒç†ä¸å¥åº·æ—¶ï¼Œä¸è¦ç‹¬è‡ªæ‰¿å—ï¼Œå¯»æ±‚ä¸“ä¸šçš„å¸®åŠ©å’Œæ”¯æŒï¼Œä¸ä»–äººåˆ†äº«ä½ çš„æ„Ÿå—ï¼Œä»–ä»¬ä¼šç»™äºˆä½ æ›´å¤šçš„åŠ›é‡å’Œæ”¯æŒã€‚\n",
      "\n",
      "åŒæ—¶ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥é€šè¿‡ä¸€äº›æ–¹æ³•æ¥æ”¹å–„å¿ƒç†å¥åº·ã€‚å°±åƒæ ‘éœ€è¦é˜³å…‰å’Œæ°´åˆ†ä¸€æ ·ï¼Œæˆ‘ä»¬ä¹Ÿéœ€è¦æ‰¾åˆ°é€‚åˆè‡ªå·±çš„æ–¹å¼æ¥æ”¾æ¾è‡ªå·±ã€‚è¿™å¯ä»¥åŒ…æ‹¬è¿åŠ¨ã€å†¥æƒ³ã€è‰ºæœ¯åˆ›ä½œã€ä¸æœ‹å‹äº¤æµç­‰ç­‰ã€‚è¿™äº›æ´»åŠ¨å¯ä»¥å¸®åŠ©æˆ‘ä»¬å‡è½»å‹åŠ›ï¼Œæå‡æƒ…ç»ªï¼Œè®©æˆ‘ä»¬é‡æ–°è·å¾—å†…å¿ƒçš„å¹³é™å’Œå¥åº·ã€‚\n",
      "\n",
      "æœ€åï¼Œè®°ä½å¿ƒç†å¥åº·æ˜¯ä¸€ä¸ªé•¿æœŸçš„è¿‡ç¨‹ï¼Œè€Œä¸æ˜¯ä¸€è¹´è€Œå°±çš„ç»“æœã€‚å°±åƒæ ‘éœ€è¦æ—¶é—´æˆé•¿ä¸€æ ·ï¼Œæˆ‘ä»¬ä¹Ÿéœ€è¦è€å¿ƒå’ŒæŒç»­çš„åŠªåŠ›æ¥æ”¹å–„è‡ªå·±çš„å¿ƒç†å¥åº·ã€‚å¦‚æœä½ æ„Ÿè§‰å¿ƒç†ä¸å¥åº·ï¼Œä¸è¦çŠ¹è±«å¯»æ±‚å¸®åŠ©ï¼Œå¹¶ç›¸ä¿¡è‡ªå·±å¯ä»¥é‡æ–°è·å¾—å†…å¿ƒçš„å¹³è¡¡å’Œå¥åº·ã€‚\n"
     ]
    }
   ],
   "source": [
    "p_model.eval()\n",
    "print(p_model.chat(tokenizer, \"æˆ‘æ„Ÿè§‰æˆ‘å¿ƒç†ä¸å¥åº·\", history=[])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9abd5eb",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c197bcc7ee801d",
   "metadata": {},
   "source": [
    "- æœ¬é¡¹ç›®çš„RAGå®ç°å­˜å‚¨åœ¨`rag`æ–‡ä»¶å¤¹ä¸‹\n",
    "- è¿™é‡Œåªåšæœ€åŸºæœ¬çš„RAGå®ç°\n",
    "- RAGçš„æ•°æ®é‡‡ç”¨QAå¯¹å½¢å¼ï¼Œå…·ä½“çš„æ•°æ®ç”Ÿæˆæ–¹æ³•è¯·å‚è€ƒ`scripts/qa_generation/README.md`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db79d017",
   "metadata": {},
   "source": [
    "### ç¯å¢ƒå®‰è£…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619674be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install numpy\n",
    "# ! pip install transformers\n",
    "# ! pip install BCEmbedding\n",
    "# ! pip install faiss-gpu\n",
    "# ! pip install peft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02c472e",
   "metadata": {},
   "source": [
    "### åŠ è½½æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b21deb8dd40eb887",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T01:16:19.269923Z",
     "start_time": "2024-04-09T01:16:19.248902Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "def data_process(dir):\n",
    "    \"\"\"è¯»å–jsonlæ–‡ä»¶ï¼Œè¿”å›é—®é¢˜å’Œç­”æ¡ˆçš„åˆ—è¡¨\"\"\"\n",
    "    with open(dir, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()   \n",
    "        lines = [json.loads(line) for line in lines]\n",
    "        questions = np.array([line['question'] for line in lines])\n",
    "        answers = np.array([line['answer'] for line in lines])\n",
    "        f.close()\n",
    "    return questions, answers\n",
    "\n",
    "questions, answers = data_process('./test.jsonl') # è¿™é‡Œä¼ å…¥ä½ çš„æ•°æ®é›†è·¯å¾„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e025356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ã€Šå„¿ç«¥å‘å±•å¿ƒç†å­¦ã€‹çš„ä¸»è¦å†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿ\n",
      "ã€Šå„¿ç«¥å‘å±•å¿ƒç†å­¦ã€‹ä¸»è¦æ¢è®¨0ä¸€18å²ä¸ªä½“å¿ƒç†å‘å±•çš„ç‰¹å¾åŠå½±å“å¿ƒç†å‘å±•çš„ç›¸å…³é—®é¢˜ï¼Œæ¶µç›–æœ‰å…³å„¿ç«¥å¿ƒç†å‘å±•çš„å¯¹è±¡ä¸ä»»åŠ¡ã€å„¿ç«¥å¿ƒç†å‘å±•çš„ç ”ç©¶æ–¹æ³•ä¸è®¾è®¡ã€å¿ƒç†å‘å±•çš„åŸºæœ¬ç†è®ºã€å½±å“å¿ƒç†å‘å±•çš„é—ä¼ ä¸ç¯å¢ƒå› ç´ ï¼Œä»¥åŠå„¿ç«¥åœ¨è®¤çŸ¥ã€æ™ºåŠ›ã€è¯­è¨€ã€æƒ…ç»ªã€äººæ ¼ã€é“å¾·ç­‰å„ä¸ªé¢†åŸŸçš„å‘å±•ç‰¹ç‚¹ã€è¶‹åŠ¿åŠå½±å“å› ç´ ç­‰ã€‚\n"
     ]
    }
   ],
   "source": [
    "print(questions[0])\n",
    "print(answers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba4df6a",
   "metadata": {},
   "source": [
    "### åŠ è½½æ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dd215dbd17148a",
   "metadata": {},
   "source": [
    "- åŠ è½½æ–‡æœ¬å‘é‡åŒ–æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f4e7fb1776aaca2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T01:16:31.562061Z",
     "start_time": "2024-04-09T01:16:23.195224Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/407/anaconda3/envs/llm/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "04/14/2024 12:03:46 - [INFO] -BCEmbedding.models.EmbeddingModel->>>    Loading from `/home/407/bigfile/tangpeng/bce-embedding-base_v1`.\n",
      "04/14/2024 12:03:47 - [INFO] -BCEmbedding.models.EmbeddingModel->>>    Execute device: cuda;\t gpu num: 4;\t use fp16: False;\t embedding pooling type: cls;\t trust remote code: True\n"
     ]
    }
   ],
   "source": [
    "from BCEmbedding import EmbeddingModel\n",
    "embedding_model = EmbeddingModel(model_name_or_path=\"./bce-embedding-base_v1\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320bea7354ed3c37",
   "metadata": {},
   "source": [
    "### å¯¹RAGæ•°æ®åº“ä¸­çš„é—®é¢˜è¿›è¡Œå‘é‡åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63c2349e1a76aee5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T01:16:46.665339Z",
     "start_time": "2024-04-09T01:16:34.731194Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:08<00:00,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2948, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "questions = questions.tolist()\n",
    "vectors = []\n",
    "for i in tqdm(range(0, len(questions), 512)):\n",
    "    batch_sens = questions[i: i + 512]\n",
    "    batch_inputs = embedding_model.encode(batch_sens, enable_tqdm=False)\n",
    "    vectors.append(batch_inputs)\n",
    "\n",
    "vectors = np.concatenate(vectors, axis=0)\n",
    "print(vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4b26a8",
   "metadata": {},
   "source": [
    "2948 è¡¨ç¤ºQAæ•°æ®é›†å¤§å°ï¼Œæœ‰2948ä¸ªQAå¯¹\n",
    "768 è¡¨ç¤ºå°†ä¸€ä¸ªé—®é¢˜è½¬åŒ–ä¸ºä¸€ä¸ª768ç»´çš„å‘é‡è¡¨ç¤º"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0806c3c2",
   "metadata": {},
   "source": [
    "### å»ºç«‹å‘é‡ç´¢å¼•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "754918991333a471",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T14:20:47.166388Z",
     "start_time": "2024-04-08T14:20:47.151423Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/14/2024 12:09:03 - [INFO] -faiss.loader->>>    Loading faiss with AVX2 support.\n",
      "04/14/2024 12:09:03 - [INFO] -faiss.loader->>>    Could not load library with AVX2 support due to:\n",
      "ModuleNotFoundError(\"No module named 'faiss.swigfaiss_avx2'\")\n",
      "04/14/2024 12:09:03 - [INFO] -faiss.loader->>>    Loading faiss.\n",
      "04/14/2024 12:09:03 - [INFO] -faiss.loader->>>    Successfully loaded faiss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading index\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<faiss.swigfaiss.IndexFlat; proxy of <Swig Object of type 'faiss::IndexFlat *' at 0x7f608c1e9d40> >"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å°†å‘é‡ä¿å­˜åˆ°å‘é‡æ•°æ®åº“ä¸­\n",
    "import faiss, os\n",
    "if not os.path.exists(\"large.index\"):\n",
    "    print(\"Building index\")\n",
    "    index = faiss.IndexFlatIP(768)              # åˆ›å»ºç´¢å¼•ï¼Œ768æ˜¯å‘é‡çš„ç»´åº¦\n",
    "    faiss.normalize_L2(vectors)                 # å¯¹å‘é‡è¿›è¡Œå½’ä¸€åŒ–\n",
    "    index.add(vectors)                          # å‘ç´¢å¼•ä¸­æ·»åŠ å‘é‡\n",
    "    faiss.write_index(index, \"large.index\")     # å°†ç´¢å¼•ä¿å­˜åˆ°æ–‡ä»¶ä¸­\n",
    "else:\n",
    "    print(\"Loading index\")\n",
    "    index = faiss.read_index(\"large.index\")     # ä»æ–‡ä»¶ä¸­åŠ è½½ç´¢å¼•\n",
    "index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63bdd12",
   "metadata": {},
   "source": [
    "### å¯¹æŸ¥è¯¢è¿›è¡Œå‘é‡åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb22e7b337753a93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T14:20:49.738883Z",
     "start_time": "2024-04-08T14:20:49.644729Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quesiton = \"æœ€è¿‘å¥½çƒ¦ï¼Œæœ‰å¾ˆå¤šäº‹æƒ…è¦åšï¼\"\n",
    "q_vector = embedding_model.encode(quesiton, enable_tqdm=False)\n",
    "q_vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0df8a4",
   "metadata": {},
   "source": [
    "### å¬å›TOP K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f57458b660804a4",
   "metadata": {},
   "source": [
    "- æ ¹æ®questionå‘é‡ï¼Œä»æ•°æ®åº“ä¸­å¬å›ä¸ä¹‹æœ€ç›¸ä¼¼çš„TOP K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cc79a4ab8efa483",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T14:30:32.425395Z",
     "start_time": "2024-04-08T14:30:32.408161Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'å®‰æ…°å•†åœºé‡Œå’Œå¦ˆå¦ˆèµ°æ•£çš„å°å¦¹å¦¹': 2278,\n",
       " 'å°å­¦ç”Ÿå¸¸ç”¨ä»€ä¹ˆæ–¹å¼æ¥è¡¨è¾¾è‡ªå·±çš„å¿ƒæƒ…ï¼Ÿ': 163,\n",
       " 'æƒ…ç»ªè¡¨è¾¾çš„æ–¹å¼æœ‰å“ªäº›ï¼Ÿ': 2428,\n",
       " 'å°å­¦ç”Ÿä¸è‰¯æƒ…ç»ªçš„è¡¨ç°æœ‰å“ªäº›ï¼Ÿ': 210,\n",
       " '2å²å„¿ç«¥ä¸»è¦ä½¿ç”¨å“ªäº›æƒ…ç»ªè°ƒèŠ‚ç­–ç•¥ï¼Ÿ': 162,\n",
       " 'æƒ…ç»ªè°ƒèŠ‚æœ‰å“ªäº›ç±»å‹ï¼Ÿ': 116,\n",
       " 'é’å°‘å¹´é€šå¸¸å¦‚ä½•æ’è§£æ€§çš„å‹åŠ›æˆ–å®£æ³„å†…å¿ƒç„¦è™‘ä¸ä¸å®‰ï¼Ÿ': 1064,\n",
       " 'æƒ…ç»ªè°ƒèŠ‚å¯ä»¥åˆ†ä¸ºå“ªä¸‰å¤§ç±»ï¼Ÿ': 139,\n",
       " 'é’å°‘å¹´é€šå¸¸å¦‚ä½•æ’è§£æ€§çš„å‹åŠ›ï¼Ÿ': 1065,\n",
       " 'å„¿ç«¥çš„åŸºæœ¬æƒ…ç»ªä¸»è¦åŒ…æ‹¬å“ªäº›ï¼Ÿ': 2565}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faiss.normalize_L2(q_vector)                     \n",
    "scores, indexes = index.search(q_vector, 10)     \n",
    "topk_result = np.array(questions)[indexes]       \n",
    "topk_result = topk_result.tolist()[0]\n",
    "indexes = indexes.tolist()[0]\n",
    "\n",
    "question2index = {}\n",
    "for question, index in zip(topk_result, indexes):\n",
    "    question2index[question] = index\n",
    "    \n",
    "question2index   # è¿”å›çš„æ˜¯top10çš„é—®é¢˜å’Œå¯¹åº”çš„ç´¢å¼•"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9b579b",
   "metadata": {},
   "source": [
    "### å¬å›è¿›è¡Œæ’åº"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dead9826c88c794",
   "metadata": {},
   "source": [
    "- ä½¿ç”¨RerankerModelå¯¹å¬å›çš„ç»“æœè¿›è¡Œæ’åºï¼Œé€‰å‡ºæœ€ç»ˆçš„TOP 3ä½œä¸ºé—®é¢˜å›ç­”çš„ä¸Šä¸‹æ–‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d54c1846f3deca4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T14:34:20.633138Z",
     "start_time": "2024-04-08T14:34:17.794869Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/14/2024 12:15:05 - [INFO] -BCEmbedding.models.RerankerModel->>>    Loading from `/home/407/bigfile/tangpeng/bce-reranker-base_v1`.\n",
      "04/14/2024 12:15:05 - [INFO] -BCEmbedding.models.RerankerModel->>>    Execute device: cuda;\t gpu num: 4;\t use fp16: False\n",
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'äº²ç¤¾ä¼šè¡Œä¸ºæƒ…ç»ªè¡¨è¾¾çš„æ–¹å¼ä¸»è¦æœ‰è¨€è¯­è¡¨æƒ…å’Œéè¨€è¯­è¡¨æƒ…ä¸¤å¤§ç±»ã€‚å…¶ä¸­è¨€è¯­è¡¨æƒ…æ˜¯é€šè¿‡ä¸€ä¸ªäººè¨€è¯­æ—¶çš„éŸ³å“ã€éŸ³é€Ÿã€éŸ³è°ƒç­‰å˜åŒ–æ¥åæ˜ ä¸åŒæƒ…ç»ªçš„ã€‚è€Œéè¨€è¯­è¡¨æƒ…åˆåŒ…æ‹¬é¢éƒ¨è¡¨æƒ…å’Œä½“æ€è¡¨æƒ…ä¸¤æ–¹é¢ã€‚ä»æƒ…ç»ªè°ƒèŠ‚è¿‡ç¨‹çš„æ¥æºåˆ’åˆ†ï¼Œå¯ä»¥å°†æƒ…ç»ªè°ƒèŠ‚åˆ†ä¸ºå†…éƒ¨è°ƒèŠ‚å’Œå¤–éƒ¨è°ƒèŠ‚ä¸¤å¤§ç±»ã€‚å…¶ä¸­ï¼Œå†…éƒ¨è°ƒèŠ‚ä¸»è¦ç”±ä¸ªä½“è‡ªèº«å®Œæˆï¼ŒåŒ…æ‹¬å¯¹ç¥ç»ç”Ÿç†ã€è®¤çŸ¥ä½“éªŒå’ŒåŠ¨ä½œè¡Œä¸ºçš„è°ƒèŠ‚ã€‚è€Œå¤–éƒ¨è°ƒèŠ‚åˆ™æ¥æºäºä¸ªä½“ä»¥å¤–çš„ç¯å¢ƒï¼Œå¦‚å¹¼å„¿ç—›å“­æ—¶ï¼Œå¤§äººçš„æŠšæ…°å¯ä»¥å¸®åŠ©å¹¼å„¿å°½å¿«åœ°ä»ç—›è‹¦ä¸­èµ°å‡ºæ¥ã€‚å¤–éƒ¨è°ƒèŠ‚å¯ä»¥åˆ†ä¸ºæ”¯æŒæ€§ç¯å¢ƒè°ƒèŠ‚å’Œç ´åæ€§ç¯å¢ƒè°ƒèŠ‚ä¸¤å¤§ç±»ã€‚'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from BCEmbedding import RerankerModel\n",
    "canidate = topk_result\n",
    "sentence_pairs = [[quesiton, passage] for passage in canidate]\n",
    "reranker_model = RerankerModel(model_name_or_path=\"./bce-reranker-base_v1\", trust_remote_code=True)\n",
    "# scores = model.compute_score(sentence_pairs)\n",
    "rerank_results = reranker_model.rerank(quesiton, canidate)\n",
    "\n",
    "context = \"\"\n",
    "for i in range(3):\n",
    "    context += answers[question2index[rerank_results[\"rerank_passages\"][i]]]\n",
    "\n",
    "context   # è¿”å›çš„æ˜¯åˆ©ç”¨ä¸æŸ¥è¯¢é—®é¢˜æœ€ç›¸ä¼¼çš„top3é—®é¢˜å¯¹åº”çš„ç­”æ¡ˆæ„å»ºçš„ä¸Šä¸‹æ–‡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67b35d9",
   "metadata": {},
   "source": [
    "### ç”Ÿæˆå›å¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18c1e1a3",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-08T14:38:58.501305Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe9c043fad0e44f490e1d898a8fe96cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ å¥½ï¼Œæˆ‘æ˜¯ä¹¦ç”ŸÂ·æµ¦è¯­ã€‚\n",
      "ä»ä½ çš„æè¿°æ¥çœ‹ï¼Œä½ å¯èƒ½éœ€è¦å¤„ç†ä¸€äº›æ¯”è¾ƒç¹é‡å’Œå¤æ‚çš„äº‹æƒ…ï¼Œéœ€è¦ä½ çš„æ³¨æ„åŠ›å’Œç²¾åŠ›æ¯”è¾ƒé›†ä¸­ï¼Œå¯èƒ½ä¹Ÿä¼šé‡åˆ°ä¸€äº›æƒ…ç»ªä¸Šçš„å›°æ‰°ï¼Œæ¯”å¦‚çƒ¦èºä¸å®‰ç­‰ã€‚\n",
      "ä½ å¯ä»¥å°è¯•ç»™è‡ªå·±åˆ—ä¸€ä¸ªæ¸…å•ï¼Œåˆ—å‡ºä½ éœ€è¦åšçš„äº‹æƒ…ï¼ŒæŒ‰ç…§ä¼˜å…ˆçº§å®‰æ’ï¼Œè¿™æ ·å¯ä»¥å¸®åŠ©ä½ æ›´å¥½åœ°å¤„ç†è¿™äº›äº‹æƒ…ã€‚\n",
      "å¦å¤–ï¼Œä½ ä¹Ÿå¯ä»¥è¯•ç€å»è¿åŠ¨ï¼Œè¿åŠ¨å¯ä»¥é‡Šæ”¾èº«ä½“å†…çš„å‹åŠ›ï¼Œç¼“è§£æƒ…ç»ªä¸Šçš„å‹åŠ›ã€‚\n",
      "å¸Œæœ›æˆ‘çš„å›ç­”èƒ½å¤Ÿå¸®åŠ©åˆ°ä½ ã€‚\n",
      "ç¥å¥½ï¼ˆğŸ³ï¼‰\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_dir = \"./Shanghai_AI_Laboratory/internlm2-chat-1_8b\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_dir, trust_remote_code=True, device_map=\"auto\")\n",
    "\n",
    "# åˆ©ç”¨è‡ªå·±å¾®è°ƒåçš„æ¨¡å‹è¿›è¡Œå¯¹è¯\n",
    "from peft import PeftModel\n",
    "model = PeftModel.from_pretrained(model, model_id=\"./chatbot/checkpoint-876\")\n",
    "\n",
    "model = model.eval()\n",
    "template = \"\"\"ä½¿ç”¨ä»¥ä¸‹ä¸Šä¸‹æ–‡æ¥å›ç­”æœ€åçš„é—®é¢˜ã€‚å¦‚æœä½ ä¸çŸ¥é“ç­”æ¡ˆï¼Œå°±è¯´ä½ ä¸çŸ¥é“ï¼Œä¸è¦è¯•å›¾ç¼–é€ ç­”æ¡ˆã€‚å°½é‡ä½¿ç­”æ¡ˆç®€æ˜æ‰¼è¦ã€‚æ€»æ˜¯åœ¨å›ç­”çš„æœ€åè¯´â€œè°¢è°¢ä½ çš„æé—®ï¼â€ã€‚\\nä¸Šä¸‹æ–‡ï¼š\"\"\" +  context + \"\\næœ€åçš„é—®é¢˜: \" + quesiton + \"\\næœ‰ç”¨çš„å›ç­”:\"\n",
    "response, history = model.chat(tokenizer, template, history=[])\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfd9227ff1f07c6",
   "metadata": {},
   "source": [
    "- ç”¨ä½œå¯¹æ¯”ï¼Œåœ¨æ²¡æœ‰ä¸Šä¸‹æ–‡çš„æƒ…å†µä¸‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "757daa05ba1750d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ å¥½ï¼Œæˆ‘æ˜¯å°ä¹ã€‚\n",
      "æœ€è¿‘æˆ‘ä¹Ÿæ˜¯æœ‰å¾ˆå¤šäº‹æƒ…è¦åšï¼Œä¸è¿‡æˆ‘ä¼šå°è¯•å»åˆ†é…ä»»åŠ¡çš„ä¼˜å…ˆçº§ï¼Œå…ˆå®Œæˆæœ€é‡è¦çš„ã€‚\n",
      "æœ‰æ—¶å€™æˆ‘ä»¬ä¼šé‡åˆ°ä¸€äº›ç´§æ€¥ä½†å¹¶ä¸é‚£ä¹ˆé‡è¦çš„ä»»åŠ¡ï¼Œå¯ä»¥å…ˆæ”¾åœ¨åé¢å®Œæˆã€‚\n",
      "å½“ä½ è§‰å¾—æœ‰äº›çƒ¦èºæ—¶ï¼Œå¯ä»¥å…ˆè®©è‡ªå·±å†·é™ä¸‹æ¥ï¼Œå†æ€è€ƒå¦‚ä½•å®‰æ’è‡ªå·±çš„æ—¶é—´ã€‚\n",
      "ç¥å¥½ï¼\n",
      "\n"
     ]
    }
   ],
   "source": [
    "template =  quesiton \n",
    "response, history = model.chat(tokenizer, template, history=[])\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
